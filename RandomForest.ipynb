{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7wsGvimC8Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':'11y79Tmi7znU_ancRPVVn5MWffJ1i_9G0'}) # replace the id with id of file that you want to access\n",
        "downloaded.GetContentFile('data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O15BYNwDBQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from sklearn import metrics\n",
        "from numpy import array\n",
        "from numpy import mean\n",
        "from numpy import cov\n",
        "from numpy.linalg import eig\n",
        "from copy import deepcopy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghCPBB6YDM55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Node:\n",
        "    def __init__(self, selected_feature, split_value, depth=None, isleaf =None):\n",
        "        self.selected_feature = selected_feature\n",
        "        self.split_value = split_value\n",
        "        self.final_label = 0\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "        self.depth = depth\n",
        "        self.isleaf = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-3b-BSuCdQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_max(labels):\n",
        "  no_of_classes = 11 \n",
        "  class_distribution = {}\n",
        "  for i in range (1, no_of_classes + 1):\n",
        "    class_distribution[i] = 0\n",
        "\n",
        "  for sample in range(labels.shape[0]):\n",
        "    class_distribution[labels[sample]] = class_distribution[labels[sample]] + 1\n",
        "\n",
        "  #return max(class_distribution.items(), key=operator.itemgetter(1))[0]\n",
        "  return max(class_distribution, key=class_distribution.get)\n",
        "\n",
        "def decisionTree(data,feature, depth, max_depth):\n",
        "  feature_best, number_best, gain =  Max_Split_division(data, feature)\n",
        "  node = Node(feature_best, number_best)\n",
        "  #node.feature_best = feature_best\n",
        " # node.number_best = number_best\n",
        "\n",
        "  if gain == 0 or max_depth <= depth or data.shape[0] < 5:\n",
        "    node1 = Node(feature_best, number_best)\n",
        "    node1.isleaf = 1\n",
        "    s = find_max(data[:,-1])\n",
        "    node1.final_label = s\n",
        "    print(\"node.final_label \",node.final_label )\n",
        "    print(\" leaf feature is \",feature_best)\n",
        "    return node1\n",
        "\n",
        "  left = []\n",
        "  right = []\n",
        "  for n in range(data.shape[0]):\n",
        "      if data[n][feature_best] < number_best:\n",
        "          left.append(data[n])\n",
        "      else:\n",
        "          right.append(data[n])\n",
        "  left = np.asarray(left)\n",
        "  right = np.asarray(right)\n",
        "\n",
        "  node.left_child = decisionTree(left,feature,depth+1,max_depth)\n",
        "  node.right_child = decisionTree(right,feature,depth+1,max_depth)\n",
        "\n",
        "  #create node object\n",
        "\n",
        "  return node\n",
        "\n",
        "def populate_inital_left_right(no_of_classes):\n",
        "    left_child = {}\n",
        "    right_child = {}\n",
        "    for i in range (1, no_of_classes + 1):\n",
        "        left_child[i] = 0\n",
        "        right_child[i] = 0\n",
        "    return left_child, right_child\n",
        "\n",
        "def get_distinct_features(features):\n",
        "  #print(\"get_distinct_features\",features)\n",
        "  mini = np.min(features)\n",
        "  maxi = np.max(features)\n",
        "  range_r = maxi - mini\n",
        "  std = range_r / 5\n",
        "  one = mini + std\n",
        "  two = one + std\n",
        "  three = two + std\n",
        "  four = three + std\n",
        "  #five = four + std\n",
        "  Lst_split_vals = [one, two, three, four]\n",
        "  #print(\"Lst_split_vals\", Lst_split_vals)\n",
        "  return Lst_split_vals\n",
        "\n",
        "\n",
        "#Calculated gain using gini impurity\n",
        "def calculate_gain(left,right, total):\n",
        "  L_sum = sum(left.values())\n",
        "  R_sum = sum(right.values())\n",
        "  # Calculate left and right impurites.\n",
        "  if L_sum == 0:\n",
        "    left_impurity = 1\n",
        "  else:\n",
        "    left_impurity = 1\n",
        "    for key,value in left.items():\n",
        "      left_impurity = left_impurity - pow((value / L_sum),2)\n",
        "    \n",
        "  if R_sum == 0:\n",
        "    right_impurity = 1\n",
        "  else:\n",
        "    right_impurity = 1\n",
        "    for key,value in right.items():\n",
        "          right_impurity = right_impurity - pow((value / R_sum),2)\n",
        "  \n",
        "  total_dist = left.copy()\n",
        "  total_dist.update(right)\n",
        "  #print(\"%%%%%%%%%%%%%%%%%%%%%\")\n",
        "  #print(left)\n",
        "  #print(right)\n",
        "  #print(\"total_dist\", total_dist)\n",
        "  parent_impurity = 1\n",
        "  for key,value in total_dist.items():\n",
        "          parent_impurity = parent_impurity - pow((value / (L_sum + R_sum)),2)\n",
        "\n",
        "  gain = parent_impurity - ((L_sum/ total) * left_impurity) - ((R_sum/ total) * right_impurity) \n",
        "  return gain\n",
        "\n",
        "def partition(data, split_val, feature):  \n",
        "    # CHANGE THIS\n",
        "    #print(data)\n",
        "    #print(\"data.shape[1]\",data.shape[1])\n",
        "    label_col = int(data.shape[1] - 1)\n",
        "    #print(\"label_col\",label_col)\n",
        "    no_of_classes = 11 #len(set(data[:,label_col]))\n",
        "    #label_col = \n",
        "    #print(\"no_of_classes\",no_of_classes)\n",
        "    left_child, right_child = populate_inital_left_right(no_of_classes)\n",
        "    for sample in range(0, int(data.shape[0])):\n",
        "        #print(data[sample][feature], split_val)\n",
        "        if data[sample][feature] < split_val:\n",
        "            left_child[data[sample][label_col]] =  left_child[data[sample][label_col]] + 1\n",
        "        else:\n",
        "            right_child[data[sample][label_col]] =  right_child[data[sample][label_col]] + 1\n",
        "\n",
        "    return left_child, right_child\n",
        "\n",
        "def Max_Split_division(data, features):\n",
        "  max_gain = 0\n",
        " \n",
        "  for feature in features:\n",
        "    numbers = get_distinct_features(data[:,feature])\n",
        "    print(\" numbers are \", numbers)\n",
        "    for number in numbers:\n",
        "      left, right = partition(data, number,  feature)\n",
        "      gain = calculate_gain(left,right, data.shape[0])\n",
        "      if gain >= max_gain:\n",
        "        global_gain = gain\n",
        "        split_value = number\n",
        "        selected_feature = feature\n",
        "  return selected_feature, split_value, global_gain\n",
        "\n",
        "def traverse(node):\n",
        "    if node == None:\n",
        "        return\n",
        "    else: \n",
        "        if node.final_label != None:\n",
        "            print(node.final_label, node.number_best, node.selected_feature)\n",
        "        traverse(node.left_child)\n",
        "        traverse(node.right_child)\n",
        "\n",
        "def find_final_labels(X, root_node):\n",
        "    print(X)\n",
        "    final_labels = []\n",
        "    for i in range(X.shape[0]):\n",
        "        curr_node = root_node\n",
        "        while(curr_node != None):\n",
        "              if curr_node.isleaf == 1:\n",
        "                  label = curr_node.final_label\n",
        "                  print(\"LABEL\", label)\n",
        "                  final_labels.append(label)\n",
        "                  break\n",
        "              feature = int(curr_node.selected_feature)\n",
        "              print(\"feature is\", feature)\n",
        "              value = float(X[i][feature])\n",
        "              print(\"VAL\",value)\n",
        "              if  value < float(curr_node.split_value):\n",
        "                  curr_node = curr_node.left_child\n",
        "              else:\n",
        "                  curr_node = curr_node.right_child\n",
        "       \n",
        "    return final_labels\n",
        "\n",
        "def TestRandomForest(root_nodes, X_test, y_test):\n",
        "    final_labels = []\n",
        "    for i in range(X_test.shape[0]):\n",
        "        for node in root_nodes:\n",
        "          voting = []\n",
        "          curr_node = node\n",
        "          while(curr_node != None):\n",
        "            if curr_node.selected_feature == None:\n",
        "              label = curr_node.final_label\n",
        "              curr_node = curr_node.left_child\n",
        "            else:\n",
        "              feature = int(curr_node.selected_feature)\n",
        "              value = float(X_test.iloc[i][feature])\n",
        "              if curr_node.split_value == None:\n",
        "                  label = curr_node.final_label\n",
        "                  curr_node = curr_node.left_child\n",
        "              elif value < float(curr_node.split_value):\n",
        "                  label = curr_node.final_label\n",
        "                  curr_node = curr_node.left_child\n",
        "              else:\n",
        "                  label = curr_node.final_label\n",
        "                  curr_node = curr_node.right_child\n",
        "          voting.append(label)\n",
        "        maximum = find_max(voting)\n",
        "        final_labels.append(maximum)\n",
        "    return final_labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iez9TqUWD9dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RandomForest():\n",
        "\n",
        "  dfs = pd.read_csv('data.csv',encoding='unicode_escape')\n",
        "  max_class = np.max(dfs['48'])\n",
        "\n",
        "  X1 = dfs.iloc[:,:48]\n",
        "  X = X1.copy()\n",
        "  for features in X1.columns:\n",
        "      max_value=X1[features].max()\n",
        "      min_value=X1[features].min()\n",
        "      X[features]=(X1[features]-min_value)/(max_value-min_value)\n",
        "\n",
        "  y = dfs.iloc[:,48:]\n",
        "  X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
        "  no_of_classes = len(y_train['48'].unique())\n",
        "\n",
        "  global_depth = 7\n",
        "  no_of_decision_trees = 4\n",
        "  obj = DecisionTree()\n",
        "  root_nodes = []\n",
        "\n",
        "  for i in range(0, no_of_decision_trees):\n",
        "    vertical_stack = pd.concat([X_train, y_train], axis=1)\n",
        "    vertical_stack = vertical_stack.sample(frac = 0.30)\n",
        "    #print(vertical_stack)\n",
        "    X1 = vertical_stack.iloc[:,:48]\n",
        "    y = vertical_stack.iloc[:,48:]\n",
        "    #y = y.rename(columns={'48': '0'})\n",
        "    #print(y)\n",
        "    x =  X1[X1.columns.to_series().sample(7)]\n",
        "    x_cat = pd.concat([x, y], axis=1)\n",
        "    print(x_cat)\n",
        "    parent_impurity = find_parent_impurity(y, no_of_classes)\n",
        "    #print(\"parent_impurity\")\n",
        "    root_node = obj.generate_level(x_cat, parent_impurity, -1, global_depth, no_of_classes)\n",
        "    root_nodes.append(root_node)\n",
        "\n",
        "\n",
        "    print(\"ACCURACY of DECISON TREE :\", i+ 1)\n",
        "    final_labels1 = find_final_labels(X_test, root_node)\n",
        "    acc1 = sklearn.metrics.accuracy_score(final_labels1, y_test.iloc[:,0].values.tolist())\n",
        "    print(\"Decision Tree Accuracy :\",acc1)\n",
        "\n",
        "\n",
        "  final_labels = TestRandomForest(root_nodes, X_test, y_test)\n",
        "  acc = sklearn.metrics.accuracy_score(final_labels, y_test.iloc[:,0].values.tolist())\n",
        "  print(\"Random forest Accuracy\",acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI_ffimWD1sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RandomForest()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}